{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7193a0",
   "metadata": {
    "papermill": {
     "duration": 0.034817,
     "end_time": "2024-09-10T18:50:25.913835",
     "exception": false,
     "start_time": "2024-09-10T18:50:25.879018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "        word-wrap: break-word;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; background-color:#cccccc; padding:5px; border:2px solid #333333;\">\n",
    "    <a href=\"https://estudios.upct.es/grado/5251/inicio\" target=\"_blank\">\n",
    "    <img src=\"https://www.upct.es/contenido/universidad/galeria/identidad-2021/logos/logos-upct/marca-upct/marca-principal/horizontal/azul.png\" alt=\"UPCT\" style=\"height:145px; width:auto;\">\n",
    "    <a href=\"https://www.um.es/web/estudios/grados/ciencia-ingenieria-datos/\" target=\"_blank\">\n",
    "    <img src=\"https://www.um.es/documents/1073494/42130150/LogosimboloUMU-positivo.png\" alt=\"UMU\" style=\"height:200px; width:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30c905",
   "metadata": {
    "papermill": {
     "duration": 0.006835,
     "end_time": "2024-09-10T18:50:25.928004",
     "exception": false,
     "start_time": "2024-09-10T18:50:25.921169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Asignatura: **Deep Learning**\n",
    "\n",
    "## Titulación: **Grado en Ciencia e Ingeniería de Datos**\n",
    "\n",
    "## Práctica 1: Introducción al Deep Learning\n",
    "### **Sesión 2/3: Limitaciones clásicas y redes neuronales actuales**\n",
    "\n",
    "**Autores**: Juan Morales Sánchez, Antonio Martínez Sánchez, José Luís Sancho Gómez y Juan Antonio Botía Blaya\n",
    "\n",
    "___\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "- Comprender las limitaciones clásicas de las redes neuronales.\n",
    "- Analizar problemas como el estancamiento del entrenamiento, la explosión de gradientes y el sobreentrenamiento.\n",
    "- Explorar soluciones prácticas a estos problemas: técnicas como inicialización de pesos, funciones de activación avanzadas, normalización y regularización.\n",
    "- Estudiar aspectos relacionados con la eficiencia computacional: cálculo tensorial, impacto del hardware de aceleración de cómputo.\n",
    "- Aplicar técnicas de optimización y regularización.\n",
    "\n",
    "### Contenidos\n",
    "- [Eficiencia computacional](#eficiencia)\n",
    "- [Operaciones con tensores](#eficiencia_tensores)\n",
    "- [Diferenciación automática](#eficiencia_diferenciacion)\n",
    "- [Cómputo eficiente sobre GPU](#eficiencia_gpu)\n",
    "- [El estancamiento del entrenamiento](#estancamiento)\n",
    "- [La explosión de gradiente](#explosion)\n",
    "- [El sobreentrenamiento](#sobreentrenamiento)\n",
    "- [Ejercicios](#ejercicios)\n",
    "\n",
    "### Bibliografía\n",
    "- [Deep Learning with Python (segunda edición)](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
    "- [Dive into Deep Learning](https://d2l.ai/)\n",
    "\n",
    "### Requisitos\n",
    "<a class='anchor' id='requisitos'></a>\n",
    "\n",
    "Se trabajará con notebooks de [Jupyter](https://jupyter.org/install) con código Python empleando como intérprete la última versión de [Miniconda](https://docs.anaconda.com/miniconda/). Se requiere la preinstalación (se recomienda utilizar [pip](https://pypi.org/project/pip/)) de los siguientes paquetes de Python:\n",
    "\n",
    "- [Numpy](https://pypi.org/project/numpy/) (computación numérica)\n",
    "- [Scipy](https://pypi.org/project/scipy/) (computación científica)\n",
    "- [Scikit-learn](https://pypi.org/project/scikit-learn/) (*Machine Learning*)\n",
    "- [Scikit-image](https://pypi.org/project/scikit-image/) (*Image Processing*)\n",
    "- [Matplotlib](https://pypi.org/project/matplotlib/) y [Seaborn](https://pypi.org/project/seaborn/) (visualización de datos)\n",
    "- [Tensorflow](https://www.tensorflow.org/) 2.x que incluye a [Keras](https://www.tensorflow.org/guide/keras) 2.x (*Deep Learning*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-before: always;\"></div>\n",
    "\n",
    "<a class='anchor' id='eficiencia'></a>\n",
    "\n",
    "## Eficiencia computacional\n",
    "\n",
    "Las redes neuronales modernas exigen una gran cantidad de cómputo debido a la complejidad de sus arquitecturas, el tamaño de los datos que procesan y las operaciones matemáticas involucradas. Aquí te detallo las principales razones:\n",
    "\n",
    "- **Modelos con un gran número de parámetros**: Las redes neuronales actuales, especialmente los modelos profundos, suelen tener millones o incluso billones de parámetros entrenables (pesos y sesgos). Durante el entrenamiento, cada parámetro necesita ser actualizado usando algoritmos de optimización como el descenso de gradiente.\n",
    "\n",
    "- **Operaciones matemáticas intensivas**: El núcleo de las redes neuronales implica cálculos altamente costosos desde el punto de vista computacional: Multiplicaciones de tensores, funciones de activación que se aplican a millones de valores en cada capa, cálculo de gradientes en el algoritmo de retropropagación para cada parámetro y capa.\n",
    "\n",
    "- **Tamaño de los datos**: Los modelos modernos entrenan con conjuntos de datos masivos, a menudo en el rango de terabytes o más, y cada dato de entrada pasa por múltiples capas, lo que implica realizar operaciones repetitivas y escalables en grandes volúmenes de datos.\n",
    "\n",
    "- **Redes profundas y arquitecturas complejas**: Las redes modernas tienen arquitecturas mucho más profundas y complejas que las redes tradicionales, por ejemplo ResNet-152 tiene más de 152 capas. Más capas implica más operaciones a realizar en cada pasada hacia adelante y hacia atrás.\n",
    "\n",
    "- **Pruebas y ajustes de hiperparámetros**: El desarrollo de redes neuronales también incluye la **optimización de hiperparámetros** y la **validación cruzada**, lo que en la práctica obliga a entrenar y evaluar múltiples versiones del modelo en diferentes subconjuntos de datos.\n",
    "\n",
    "- **Inferencia en producción**: Incluso después de entrenar un modelo, la inferencia en producción puede ser costosa. GPT-3, por ejemplo, ya requiería varios gigabytes de memoria y tiempo de cálculo significativo para generar texto.\n",
    "\n",
    "Repasaremos a continuación, y de forma práctica, algunos de estos aspectos relevantes para la eficiencia de cómputo en *Deep Learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50ea7f",
   "metadata": {},
   "source": [
    "<a class='anchor' id='eficiencia_tensores'></a>\n",
    "\n",
    "### Operaciones con tensores\n",
    "\n",
    "Los tensores son esenciales para manejar y transformar datos numéricos de manera eficiente en arquitecturas complejas. Estas operaciones se realizan de manera eficiente utilizando librerías optimizadas como Numpy, TensorFlow, PyTorch o JAX, que en muchos casos ofrecen compatibilidad directa con hardware de aceleración del cómputo (GPUs y TPUs) así como capacidad de paralelización entre diferentes dispositivos.\n",
    "\n",
    "Los tensores fluyen a través de la red desde las capas de entrada hasta las capas de salida, y las operaciones se estructuran como un grafo de computación. Por tanto, los tensores son la base sobre la que se construyen los modelos de *Deep learning*.\n",
    "\n",
    "#### Ejemplo comparativo de la eficiencia computacional de las operaciones tensoriales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimación del tiempo de cómputo de operaciones con implementación ingenua\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x\n",
    "\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(5000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Tiempo de cómputo : {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684368d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimación del tiempo de cómputo de operaciones con implementación tensorial\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(5000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Tiempo de cómputo: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad3444",
   "metadata": {},
   "source": [
    "<a class='anchor' id='eficiencia_diferenciacion'></a>\n",
    "\n",
    "### Optimización basada en gradientes: diferenciación automática\n",
    "\n",
    "En matemáticas y álgebra computacional, la **diferenciación automática** o **autodiferenciación** hace referencia a un conjunto de técnicas para evaluar la derivada parcial de una función especificada por una secuencia de operaciones de cómputo. La diferenciación automática es la idea central para automatizar el cálculo simultáneo de los valores numéricos de funciones arbitrariamente complejas y de sus derivadas, sin necesidad de la representación simbólica de la función o de su derivada, solo se requiere la secuencia o algoritmo que aplica la función. La autodiferenciación es en teoría exacta, y mucho más eficiente computacionalmente, en comparación con algoritmos simbólicos u otro métodos numéricos tradicionales basados en diferencias finitas.\n",
    "\n",
    "La diferenciación automática explota el hecho de que cada cálculo, por complicado que sea, se ejecuta una secuencia de operaciones aritméticas elementales (suma, resta, multiplicación, división, etc.) y funciones básicas (exp, log, sin, cos, etc.). Al aplicar la regla de la cadena repetidamente a estas operaciones, las derivadas parciales de orden arbitrario se pueden calcular automáticamente.\n",
    "\n",
    "Las operaciones con tensores en marcos de trabajo como TensorFlow y PyTorch son diferenciables. Esto significa que estos *frameworks* pueden calcular gradientes automáticamente de dichas operaciones, para optimizar los parámetros del modelo durante el entrenamiento.\n",
    "\n",
    "### Grafos de computación\n",
    "\n",
    "La diferenciación automática puede funcionar en modo [*forward* o *backward*](https://pytorch.org/blog/overview-of-pytorch-autograd-engine/), haciendo referencia a que \n",
    "\n",
    "* en *forward* o hacia delante: podemos aprovechar para calcular los gradientes conforme vamos recorriendo la red neuronal hacia delante, mientras vamos haciendo también la inferencia de la muestra de entrada\n",
    "\n",
    "* en *backward* o hacia atrás: una vez hemos hecho la inferencia y calculamos la pérdida, construimos el grafo que nos permite el cómputo de los gradientes en cadena y en tiempo de ejecución.\n",
    "\n",
    "Para diferenciar automáticamente, [TensorFlow](https://www.tensorflow.org/guide/autodiff) necesita recordar qué operaciones suceden y en qué orden durante el paso hacia adelante. Luego, durante el paso hacia atrás, TensorFlow recorre esta lista de operaciones en orden inverso para calcular los gradientes.\n",
    "\n",
    "TensorFlow proporciona la API `tf.GradientTape` para la diferenciación automática, es decir, para calcular el gradiente de una operación con respecto a ciertas entradas, generalmente del tipo `tf.Variable`. TensorFlow \"graba\" las operaciones matemáticas relevantes ejecutadas dentro de un contexto denominado `tf.GradientTape` en una \"cinta\". En una segunda fase, TensorFlow utiliza dicha \"cinta\" (grafo de computación) para calcular, mediante la diferenciación en modo inverso, los gradientes de cada operación matemática previamente \"grabada\".\n",
    "\n",
    "Veamos un par de ejemplos sencillos en TensorFlow para ilustrar el funcionamiento interno de `tf.GradientTape`:\n",
    "\n",
    "1. Una función simple $y = x^2 + 3x + 5$, donde `tf.GradientTape` registra las operaciones realizadas en $y$, para calcular el gradiente respecto a $x$.\n",
    "2. Una función más compleja $z = 3x^2 + 2xy + y^2$, donde `tf.GradientTape` registra las operaciones realizadas en $z$, para calcular gradientes respecto a $x$ e $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44297ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir una función simple\n",
    "@tf.function\n",
    "def simple_function(x):\n",
    "    return x**2 + 3 * x + 5\n",
    "\n",
    "# Crear un grafo de computación con tf.GradientTape\n",
    "x = tf.Variable(2.0)  # Variable inicial\n",
    "with tf.GradientTape() as tape:\n",
    "    y = simple_function(x)  # Calcula y en función de x\n",
    "\n",
    "# Calcular el gradiente de y respecto a x\n",
    "gradient = tape.gradient(y, x)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Valor de la variable (x): {x.numpy()}\")\n",
    "print(f\"Valor de la función (y): {y.numpy()}\")\n",
    "print(f\"Gradiente de y respecto a x (dy/dx): {gradient.numpy()}\\n\")\n",
    "\n",
    "# Un caso más complejo con múltiples variables\n",
    "@tf.function\n",
    "def multi_variable_function(x, y):\n",
    "    return 3 * x**2 + 2 * x * y + y**2\n",
    "\n",
    "# Crear variables\n",
    "x_var = tf.Variable(1.0)\n",
    "y_var = tf.Variable(2.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = multi_variable_function(x_var, y_var)  # Calcula z\n",
    "\n",
    "# Calcular gradientes de z respecto a x_var y y_var\n",
    "gradients = tape.gradient(z, [x_var, y_var])\n",
    "\n",
    "# Mostrar resultados del caso múltiple\n",
    "print(f\"Valor de la variable (x): {x.numpy()}\")\n",
    "print(f\"Valor de la variable (y): {y.numpy()}\")\n",
    "print(f\"Valor de la función (z): {z.numpy()}\")\n",
    "print(f\"Gradiente de z respecto a x (dz/dx): {gradients[0].numpy()}\")\n",
    "print(f\"Gradiente de z respecto a y (dz/dy): {gradients[1].numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56566c18",
   "metadata": {},
   "source": [
    "<a class='anchor' id='eficiencia_gpu'></a>\n",
    "\n",
    "### Paralelización y cómputo eficiente sobre GPU\n",
    "\n",
    "Las GPUs están optimizadas para realizar cálculos tensoriales paralelos, como productos matriciales y convoluciones, de manera mucho más rápida que una CPU. También pueden combina múltiples operaciones en un único kernel para reducir la latencia y mejorar la eficiencia (Tensor Cores en GPUs NVIDIA).\n",
    "\n",
    "TensorFlow está diseñado para aprovechar las características de las GPUs y también TPUs. Si hay una GPU compatible instalada y configurada con CUDA/cuDNN, TensorFlow utilizará la GPU de manera predeterminada para operaciones intensivas como multiplicaciones de matrices y convoluciones, aunque también es posible realizar una detección automática de la presencia de GPU en el sistema, y asignar el cómputo al dispositivo preferido (CPU o GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar disponibilidad de GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs disponibles:\", gpus)\n",
    "device = '/GPU:0' if gpus else '/CPU:0'\n",
    "print(f\"Ejecutando en: {device}\")\n",
    "\n",
    "# Definir una operación intensiva\n",
    "with tf.device(device):  # Especificar CPU/GPU\n",
    "    x = tf.random.normal([5000, 5000])\n",
    "    y = tf.matmul(x, x)  # Producto matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbc109",
   "metadata": {},
   "source": [
    "<a class='anchor' id='estancamiento'></a>\n",
    "\n",
    "## Problemas numéricos: el estancamiento del entrenamiento\n",
    "\n",
    "El estancamiento es un problema clásico que puede aparecer durante el entrenamiento de redes neuronales, debido al **desvanecimiento del gradiente**, que ocurre cuando se utiliza el algoritmo de Descenso Estocástico de Gradiente (SGD) para entrenar redes neuronales profundas, especialmente cuando se emplean funciones de activación como `sigmoid` o `tanh`. Este fenómeno se caracteriza por:\n",
    "\n",
    "1. **Propagación de gradientes pequeños**:\n",
    "   - Durante la retropropagación, los gradientes calculados para las capas más profundas (cercanas a la entrada) se multiplican repetidamente por las derivadas de las funciones de activación. Si estas derivadas son pequeñas, los gradientes disminuyen exponencialmente conforme retroceden hacia las primeras capas.\n",
    "\n",
    "2. **Pesos que dejan de actualizarse**:\n",
    "   - Gradientes extremadamente pequeños producen actualizaciones insignificantes para los pesos de las capas más cercanas a la entrada, lo que provoca que estas capas apenas aprendan.\n",
    "\n",
    "3. **Entrenamiento estancado**:\n",
    "   - El modelo tarda en converger o no mejora, lo cual se observa en curvas planas de pérdida a lo largo de las épocas.\n",
    "\n",
    "Las soluciones habituales para este problema son:\n",
    "1. **ReLU (Rectified Linear Unit)**:\n",
    "   - Evita el desvanecimiento porque su derivada es constante (1 para valores positivos).\n",
    "   - Ejemplo:\n",
    "   ```python\n",
    "      model = models.Sequential([\n",
    "         layers.Dense(64, activation='relu', input_shape=(2,)),\n",
    "         layers.Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "   ```\n",
    "2. **Batch Normalization**:\n",
    "   - Normaliza las entradas de cada capa, reduciendo la dependencia de valores extremos.\n",
    "   - Ejemplo:\n",
    "   ```python\n",
    "      model = models.Sequential([\n",
    "         layers.Dense(100, activation='relu', input_shape=(10, )),\n",
    "         layers.BatchNormalization(),\n",
    "         layers.Dense(5, activation='softmax')\n",
    "      ])\n",
    "   ```\n",
    "3. **Optimizadores avanzados**:\n",
    "   - Optimizadores como Adam ajustan dinámicamente la tasa de aprendizaje, mitigando el problema.\n",
    "   - Ejemplo:\n",
    "   ```python\n",
    "      optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "   ```\n",
    "4. **Inicialización de pesos**:\n",
    "   - Inicializaciones como ``Xavier`` (también denominada ``glorot_uniform`` en TensorFlow), diseñada para funciones de activación como ``sigmoid`` o ``tanh``, buscan mantener la varianza de las activaciones a través de las capas de la red, reduciendo la saturación de las funciones de activación y previniendo que los gradientes se vuelvan demasiado pequeños o grandes.\n",
    "   - Ejemplo:\n",
    "   ```python\n",
    "      model = Sequential([\n",
    "         layers.Dense(128, kernel_initializer = 'glorot_uniform'),\n",
    "         layers.Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "   ```\n",
    "\n",
    "En el ejemplo que se muestra a continuación, el modelo con activación `sigmoid`, sin inicialización de pesos, y optimizador SGD muestra estancamiento. Esto ilustra claramente el efecto del desvanecimiento del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab28969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de red neuronal en TensorFlow que muestra el problema de estancamiento del entrenamiento\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar un dataset sintético\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "y = x ** 2  # Relación no lineal\n",
    "\n",
    "# Dividir los datos\n",
    "x_train = x.reshape(-1, 1)\n",
    "y_train = y.reshape(-1, 1)\n",
    "\n",
    "# Crear un modelo de red profunda para provocar desvanecimiento del gradiente\n",
    "model = Sequential([\n",
    "    layers.Dense(128, activation='sigmoid', input_shape=(1,), kernel_initializer='zeros'),\n",
    "    layers.Dense(128, activation='sigmoid', kernel_initializer='zeros'),\n",
    "    layers.Dense(128, activation='sigmoid', kernel_initializer='zeros'),\n",
    "    layers.Dense(128, activation='sigmoid', kernel_initializer='zeros'),\n",
    "    layers.Dense(128, activation='sigmoid', kernel_initializer='zeros'),\n",
    "    layers.Dense(1)  # Salida de una sola neurona\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "# Entrenamiento\n",
    "history_stagnant = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Representar las pérdidas del modelo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_stagnant.history['loss'], label=f\"Estancamiento (sigmoid + SGD) -> Pérdida mínima: {min(history_stagnant.history['loss']):.4f}\")\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Pérdidas estancadas')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf64f84",
   "metadata": {},
   "source": [
    "<a class='anchor' id='explosion'></a>\n",
    "\n",
    "## Problemas numéricos: la explosión de gradiente\n",
    "\n",
    "El **problema de la explosión de gradiente** ocurre durante el entrenamiento de redes neuronales, especialmente en redes profundas o recurrentes. Se caracteriza por un crecimiento descontrolado de los gradientes a medida que estos se propagan hacia atrás, lo que puede llevar a que los pesos del modelo tomen valores extremadamente grandes y hagan que el entrenamiento sea inestable o que diverja, ya que la función de pérdida puede alcanzar valores muy altos o incluso errores numéricos (``NaN``).\n",
    "\n",
    "Hay que recordar que para actualizar los pesos durante la retropropagación se utiliza la regla de la cadena, de manera que cada gradiente se calcula multiplicando los gradientes de las capas anteriores. En una red profunda este cálculo implica multiplicar muchos valores (uno por capa).\n",
    "\n",
    "Por tanto, es fácil intuir que explosión de gradiente puede ocurrir con mayor probabilidad si:\n",
    "   - La red es muy profunda.\n",
    "   - Los pesos están mal inicializados.\n",
    "   - Las funciones de activación tienen derivadas grandes.\n",
    "\n",
    "Algunas soluciones para mitigar la posibilidad de explosión de gradiente son:\n",
    "\n",
    "1. **Saturación de gradientes**:\n",
    "   - Restringe los gradientes para que no excedan un valor máximo predeterminado.\n",
    "   - Ejemplo:\n",
    "     ```python\n",
    "     optimizer = optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "     ```\n",
    "\n",
    "2. **Inicialización adecuada de pesos**:\n",
    "   - Utiliza esquemas de inicialización como **Xavier** o **He**, que están diseñados para mantener los gradientes en un rango estable.\n",
    "   - Ejemplo:\n",
    "     ```python\n",
    "     model = Sequential([\n",
    "         layers.Dense(128, activation='relu', kernel_initializer = 'he_normal'),\n",
    "         layers.Dense(1, activation='sigmoid')\n",
    "     ])\n",
    "     ```\n",
    "\n",
    "3. **Funciones de activación adecuadas**:\n",
    "   - **ReLU** y variantes como **Leaky ReLU** suelen ser menos propensas a la explosión de gradiente que funciones como **tanh** o **sigmoid**, porque tienen derivadas controladas.\n",
    "   - Ejemplo:\n",
    "      ```python\n",
    "      model = models.Sequential([\n",
    "         layers.Dense(64, activation='relu'),\n",
    "         layers.Dense(1, activation='sigmoid')\n",
    "      ])\n",
    "      ```\n",
    "4. **Normalización de gradientes**:\n",
    "   - Técnicas como el ``BatchNormalization`` estabilizan el flujo de gradientes.\n",
    "   - Ejemplo:\n",
    "     ```python\n",
    "     model = models.Sequential([\n",
    "         layers.Dense(100, activation='relu'),\n",
    "         layers.BatchNormalization(),\n",
    "         layers.Dense(5, activation='softmax')\n",
    "     ])\n",
    "     ```\n",
    "5. **Tasas de aprendizaje más pequeñas**:\n",
    "   - Usar un valor bajo para la tasa de aprendizaje puede mitigar el problema, ya que las actualizaciones de los pesos serán más controladas.\n",
    "   - Ejemplo:\n",
    "     ```python\n",
    "     optimizer = optimizers.SGD(learning_rate=0.00001)\n",
    "     ```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c76f96",
   "metadata": {},
   "source": [
    "<a class='anchor' id='sobreentrenamiento'></a>\n",
    "\n",
    "## El sobreentrenamiento\n",
    "\n",
    "El **sobreentrenamiento** (u *overfitting*) en *Deep Learning* ocurre cuando un modelo recuerda en exceso los detalles y patrones específicos del conjunto de entrenamiento, incluyendo el ruido o anomalías en los datos, pero no generaliza bien a datos nuevos o no vistos (como los de validación o test). Esto produce un rendimiento alto en el conjunto de entrenamiento pero bajo en los otros conjuntos no conocidos. Las causas más comunes del sobreentrenamiento suelen ser:\n",
    "\n",
    "1. **Modelo demasiado complejo**:\n",
    "   - Redes neuronales con demasiados parámetros (como muchas capas o neuronas) tienden a memorizar los datos de entrenamiento en lugar de aprender patrones generales.\n",
    "\n",
    "2. **Cantidad insuficiente de datos**:\n",
    "   - Con pocos datos de entrenamiento, el modelo tiene menos ejemplos para aprender patrones generales y tiende a ajustarse a los datos disponibles.\n",
    "\n",
    "3. **Ruido en los datos**:\n",
    "   - Si los datos de entrenamiento contienen errores, inconsistencias o ruido, el modelo puede ajustarse a estos valores irrelevantes.\n",
    "\n",
    "4. **Entrenamiento excesivo**:\n",
    "   - Continuar entrenando después de que el modelo ha alcanzado su punto óptimo en el conjunto de validación puede llevar a que aprenda patrones específicos no útiles.\n",
    "\n",
    "El sobreentrenamiento se puede identificar si representamos las curvas de pérdida durante el entrenamiento, ya que la **pérdida de entrenamiento** sigue disminuyendo debido a que el modelo ajusta sus parámetros a los datos, pero la **pérdida de validación** comienza a aumentar después de un punto inflexión (sobreentrenamiento), a partir del cual el modelo empieza a memorizar en lugar de generalizar. Por tanto, son indicadores del sobreentrenamiento:\n",
    "\n",
    "1. **La pérdida de entrenamiento disminuye mientras que la pérdida de validación aumenta**:\n",
    "   - Este comportamiento puede observarse en las curvas de pérdida durante el entrenamiento.\n",
    "   \n",
    "2. **Discrepancia entre métricas de entrenamiento y validación**:\n",
    "   - Alta precisión en el entrenamiento, pero baja precisión en la validación o prueba.\n",
    "\n",
    "3. **Inconsistencia en la predicción**:\n",
    "   - El modelo funciona bien con datos de entrenamiento, pero falla en generalizar a nuevos ejemplos.\n",
    "\n",
    "Entre las soluciones soluciones al sobreentrenamiento se encuentran:\n",
    "\n",
    "1. **Regularización**:\n",
    "   - Técnicas como ``Dropout``, regularización de pesos L1/L2, decaimiento de pesos (*Weight Decay*) penalizan los pesos grandes del modelo, promoviendo soluciones más simples.\n",
    "   - Ejemplos:\n",
    "      - Aplicación de un factor de ``Dropout`` del 20%, desconectando aleatoriamente un porcentaje de conexiones neuronales:\n",
    "        ```python\n",
    "        model = models.Sequential([\n",
    "           layers.Dense(100, activation='relu', input_shape=(10, )),\n",
    "           layers.Dropout(0.2),\n",
    "           layers.Dense(5, activation='softmax')\n",
    "        ])\n",
    "        ```\n",
    "      - Regularización L2 en capas concretas de la red (penalización sobre el gradiente por pesos elevados):\n",
    "        ```python\n",
    "        model = Sequential([\n",
    "           layers.Dense(64, activation='relu', input_shape=(2,),\n",
    "                        kernel_regularizer=regularizers.l2(0.01)),\n",
    "           layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01))\n",
    "        ])\n",
    "        ```\n",
    "      - Ajuste de la tasa de aprendizaje y decaimiento sobre todos los pesos (regularización L2 a nivel de optimizador):\n",
    "        ```python\n",
    "        optimizer = optimizers.Adam(weight_decay=0.01)\n",
    "        ```\n",
    "\n",
    "2. **Parada anticipada (*Early Stopping*)**:\n",
    "   - Detener el entrenamiento cuando la pérdida de validación deja de mejorar.\n",
    "   - Ejemplo:\n",
    "     ```python\n",
    "     from tensorflow.keras.callbacks import EarlyStopping\n",
    "         early_stopping = EarlyStopping(\n",
    "         monitor = 'val_loss', \n",
    "         patience = 5, \n",
    "         restore_best_weights = True\n",
    "     )\n",
    "     history = model.fit(\n",
    "         x_train, y_train,\n",
    "         epochs=100,\n",
    "         callbacks = [early_stopping]\n",
    "     )\n",
    "     ```\n",
    "\n",
    "3. **Aumentación de datos**:\n",
    "   - Crear nuevas variaciones de los datos de entrenamiento (rotaciones, zoom, cambios de brillo) para mejorar la generalización.\n",
    "<!---\n",
    "   - Ejemplo:\n",
    "     ```python\n",
    "     model = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        ......\n",
    "     ])\n",
    "   ```\n",
    "-->\n",
    "\n",
    "4. **Conjuntos de datos más numeroso**:\n",
    "   - Obtener más datos para que el modelo tenga suficientes ejemplos para aprender patrones generales.\n",
    "\n",
    "5. **Modelos más simples**:\n",
    "   - Reducir la complejidad del modelo (menos capas o menos neuronas) o ajuste de hiperparámetros.\n",
    "\n",
    "Veamos un pequeño ejemplo de un problema de regresión en el que se puede observar el sobreentrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c086e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar un dataset sintético\n",
    "np.random.seed(88) \n",
    "x = np.linspace(-1, 1, 1000)\n",
    "y = x ** 2 + np.random.normal(0, 0.5, 1000)  # Relación no lineal con ruido\n",
    "\n",
    "# Dividir los datos\n",
    "x_train = x[:800].reshape(-1, 1)\n",
    "y_train = y[:800].reshape(-1, 1)\n",
    "x_val = x[800:].reshape(-1, 1)\n",
    "y_val = y[800:].reshape(-1, 1)\n",
    "\n",
    "# Crear un modelo sencillo\n",
    "model = Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(1,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Graficar las curvas de pérdida\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Efecto del sobreentrenamiento')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Analizar el sobreentrenamiento\n",
    "train_loss = history.history['loss'][-1]\n",
    "val_loss = history.history['val_loss'][-1]\n",
    "print(f\"Pérdida final en entrenamiento: {train_loss:.4f}\")\n",
    "print(f\"Pérdida final en validación: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c768f5b",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ejercicios'></a>\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "**E1:** Partiendo del código proporcionado en el apartado previo referido al problema del [estancamiento del entrenamiento](#estancamiento), evalúe **por separado** y de **forma combinada** las soluciones básicas mencionadas en el referido apartado, y:\n",
    "\n",
    "1. **Represente gráficamente de forma conjunta la función de pérdidas** de la versión inicial y todas las soluciones (individuales o combinación de ellas).\n",
    "\n",
    "2. **Elabore una tabla** que muestre para cada una de las soluciones (o combinación de ellas) **el valor de la pérdida mínima alcanzada y la época aproximada de saturación del entrenamiento** (*codo* de la curva de pérdida), indicando cual considera que es la mejor solución.\n",
    "\n",
    "\n",
    "**E2:** Partiendo del código proporcionado en el apartado previo referido al problema del [sobreentrenamiento](#sobreentrenamiento), evalúe **por separado** y de **forma combinada** las soluciones básicas mencionadas en el referido apartado, y:\n",
    "\n",
    "1. **Represente gráficamente de forma conjunta la función de pérdidas** de la versión inicial y todas las soluciones (individuales o combinación de ellas).\n",
    "\n",
    "2. **Elabore una tabla** que muestre para cada una de las soluciones (o combinación de ellas) **el valor de la pérdida mínima alcanzada y la época aproximada de saturación del entrenamiento** (*codo* de la curva de pérdida), indicando cual considera que es la mejor solución."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.503705,
   "end_time": "2024-09-10T18:50:39.408748",
   "environment_variables": {},
   "exception": null,
   "input_path": "./s02.ipynb",
   "output_path": "/home/rufernan/local/DOCENCIA/_2024_2025/C1_PI/PRACTICAS/s02/s02.ipynb",
   "parameters": {},
   "start_time": "2024-09-10T18:50:24.905043",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
