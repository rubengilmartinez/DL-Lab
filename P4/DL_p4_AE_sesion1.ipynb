{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7193a0",
   "metadata": {
    "papermill": {
     "duration": 0.034817,
     "end_time": "2024-09-10T18:50:25.913835",
     "exception": false,
     "start_time": "2024-09-10T18:50:25.879018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "        word-wrap: break-word;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; background-color:#cccccc; padding:5px; border:2px solid #333333;\">\n",
    "    <a href=\"https://estudios.upct.es/grado/5251/inicio\" target=\"_blank\">\n",
    "    <img src=\"https://www.upct.es/contenido/universidad/galeria/identidad-2021/logos/logos-upct/marca-upct/marca-principal/horizontal/azul.png\" alt=\"UPCT\" style=\"height:145px; width:auto;\">\n",
    "    <a href=\"https://www.um.es/web/estudios/grados/ciencia-ingenieria-datos/\" target=\"_blank\">\n",
    "    <img src=\"https://www.um.es/documents/1073494/42130150/LogosimboloUMU-positivo.png\" alt=\"UMU\" style=\"height:200px; width:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30c905",
   "metadata": {
    "papermill": {
     "duration": 0.006835,
     "end_time": "2024-09-10T18:50:25.928004",
     "exception": false,
     "start_time": "2024-09-10T18:50:25.921169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Asignatura: **Deep Learning**\n",
    "\n",
    "## Titulación: **Grado en Ciencia e Ingeniería de Datos**\n",
    "\n",
    "## Práctica 4: Autocodificadores\n",
    "### **Sesión 1/3: Autocodificadores para detección de anomalías**\n",
    "\n",
    "**Autores**: Juan Morales Sánchez, Antonio Martínez Sánchez, José Luís Sancho Gómez y Juan Antonio Botía Blaya\n",
    "___\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "- Definición de la arquitectura básica de un *autoencoder* (encoder y decoder).\n",
    "- Diseño de un *autoencoder* totalmente conectado.\n",
    "- Comprender la reducción de dimensionalidad asociada al espacio latente.\n",
    "- Representar la reconstrucción de señal realizada por un *autoencoder*.\n",
    "- Aplicación a la detección de anomalías en series temporales.\n",
    "\n",
    "### Contenidos\n",
    "- [El dataset ECG5000](#dataset)\n",
    "- [Concepto de *autoencoder*](#concepto)\n",
    "- [*Autoencoder* totalmente conectado](#autoencoder)\n",
    "- [Ejercicios](#ejercicios)\n",
    "\n",
    "### Requisitos \n",
    "<a class='anchor' id='requisitos'></a>\n",
    "\n",
    "- [Numpy](https://pypi.org/project/numpy/) (computación numérica)\n",
    "- [Scipy](https://pypi.org/project/scipy/) (computación científica)\n",
    "- [Scikit-learn](https://pypi.org/project/scikit-learn/) (*Machine Learning*)\n",
    "- [Scikit-image](https://pypi.org/project/scikit-image/) (*Image Processing*)\n",
    "- [Matplotlib](https://pypi.org/project/matplotlib/) y [Seaborn](https://pypi.org/project/seaborn/) (visualización de datos)\n",
    "- [Tensorflow](https://www.tensorflow.org/) 2.x que incluye a [Keras](https://www.tensorflow.org/guide/keras) 2.x (*Deep Learning*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3722b93",
   "metadata": {},
   "source": [
    "<a class='anchor' id='dataset'></a>\n",
    "\n",
    "## El dataset ECG5000\n",
    "\n",
    "El [dataset ECG5000](https://www.timeseriesclassification.com/description.php?Dataset=ECG5000) es un conjunto de datos compuesto por series temporales, que contienen señales de electrocardiogramas (ECG) utilizadas principalmente para la detección de anomalías cardíacas. Originalmente el dataset contiene diferentes tipos etiquetados de anomalías: anomalía tipo R-on-T, anomalía tipo PVC (extrasístole ventricular), anomalía tipo SP (latido supernormal) y anomalía tipo UB (latido desconocido). Sin embargo, en esta práctica se utilizará una [versión simplificada del dataset ECG5000](http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv), que tiene un etiquetado binario (clase \"normal\" y clase \"anómala\"), que resulta más adecuado para el problema de detección de anomalías que se pretende abordar aquí.\n",
    "\n",
    "### Características del dataset ECG5000 con etiquetado binario\n",
    "- **Origen**: Derivado de la base de datos de ECG de BIDMC (Beth Israel Deaconess Medical Center).\n",
    "- **Cantidad de muestras**: 5000 registros de ECG.\n",
    "- **Longitud de cada serie temporal**: 140 instantes temporales.\n",
    "- **Etiquetas**: (la última columna de cada registro es la etiqueta, y las 140 restantes son la señal ECG)\n",
    "  - Clase 1: \"normal\" (se considerará conocida durante el aprendizaje)\n",
    "  - Clase 0: \"anómala\" (se considerará desconocida durante el aprendizaje)\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; padding:5px solid #333333;\">\n",
    "    <img src=\"imgs/dataset_ECG5000.png\" style=\"height:500px; width:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4f4ce",
   "metadata": {},
   "source": [
    "<a class='anchor' id='concepto'></a>\n",
    "\n",
    "## Concepto de *autoencoder*\n",
    "\n",
    "Los *autoencoders*, codificadores automáticos o autocodificadores, son redes neuronales diseñadas para aprender representaciones (codificaciones) compactas y eficientes de los datos de entrada, de forma no supervisada. Su estructura básica se compone de dos partes:\n",
    "\n",
    "- **Codificador (*Encoder*):** Transforma la entrada en una representación interna (codificación) de menor dimensión, dentro del denominado espacio latente (z).\n",
    "- **Decodificador (*Decoder*):** Reconstruye la entrada original a partir de esa representación en dicho espacio latente.\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; padding:5px solid #333333;\">\n",
    "    <img src=\"imgs/AE_pyramid.png\" style=\"height:300px; width:auto\">\n",
    "</div>\n",
    "\n",
    "### Variantes de *autoencoders*\n",
    "\n",
    "1. ***Autoencoder* totalmente conectado:**  \n",
    "   Emplea capas totalmente conectadas y aprende a reconstruir la entrada minimizando el error de reconstrucción. La representación intermedia es determinista y se utiliza principalmente para reducción de dimensionalidad (compresión, detección de anomalías, etc.), pero capturando relaciones no lineales, a diferencia de otras técnicas como PCA. Se probará durante la sesión 1 de esta práctica 4.\n",
    "\n",
    "2. ***Sparse autoencoder*:**  \n",
    "   Incorpora restricciones de dispersión en la representación latente para fomentar que solo un subconjunto de neuronas se active, lo que mejora la interpretabilidad y captura de características importantes. Se probará durante la sesión 2 de esta práctica 4.\n",
    "\n",
    "3. ***Denoising autoencoder*:**  \n",
    "   Se entrena para reconstruir la entrada original a partir de versiones corrompidas o ruidosas de la misma, lo que lo hace útil para aprender representaciones robustas y para tareas de eliminación de ruido. No se probará en esta práctica 4, ya que la idea es similar a la ensayada durante la sesión 2 de la práctica 2 con la U-Net.\n",
    "\n",
    "4. ***Autoencoder* convolucional (*Convolutional AutoEncoder* o CAE):**  \n",
    "   Se aplica típicamente a imágenes, y es similar a un *autoencoder* totalmente conectado, pero utiliza capas convolucionales que sustituyen a las capas densas tradicionales, lo que habitualmente permite aprender patrones locales y estructuras espaciales de manera más eficiente. Se probará durante la sesión 2 de esta práctica 4.\n",
    "\n",
    "5. ***Autoencoder* variacional (*Variational AutoEncoder* o VAE):**  \n",
    "   Introduce un enfoque probabilístico, modelando la representación latente como una distribución de probabilidad (generalmente gaussiana). Además del error de reconstrucción, se añade un término de divergencia Kullback-Leibler para regularizar la distribución del espacio latente. Esto permite generar nuevos datos tomando muestras aleatorias de dicho espacio latente. Se probará durante la sesión 3 de esta práctica 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049ce4c",
   "metadata": {},
   "source": [
    "<a class='anchor' id='autoencoder'></a>\n",
    "\n",
    "## *Autoencoder* totalmente conectado\n",
    "\n",
    "Para diseñar un autoencoder totalmente conectado en ```tensorflow``` lo habitual es construir 3 modelos diferentes, pero enlazados: codificador, decodificador y autocodificador. Utilizando la definición funcional de modelos de ```tensorflow``` la implementación podría seguir esta estructura:\n",
    "\n",
    "**Codificador**\n",
    "```python\n",
    "input = keras.layers.Input(shape=INPUT_SHAPE)                   # Nivel 0 (espacio base)\n",
    "x = keras.layers.Dense(DIM_1, activation=ACTIVATION)(input)     # Nivel 1\n",
    "x = keras.layers.Dense(DIM_2, activation=ACTIVATION)(x)         # Nivel 2\n",
    "x = keras.layers.Dense(DIM_3, activation=ACTIVATION)(x)         # Nivel 3\n",
    ".                                                               .\n",
    ".                                                               .\n",
    "encoded_z = keras.layers.Dense(LATENT_DIM)(x)                   # Nivel N (espacio latente)\n",
    "encoder = keras.Model(input, encoded_z)                         # Modelo codificador: datos de entrada -> codificación en espacio latente\n",
    "```\n",
    "\n",
    "**Decodificador**\n",
    "```python\n",
    ".                                                               .\n",
    ".                                                               .\n",
    "x = keras.layers.Dense(DIM_3, activation=ACTIVATION)(encoded_z) # Nivel 3\n",
    "x = keras.layers.Dense(DIM_2, activation=ACTIVATION)(x)         # Nivel 2\n",
    "x = keras.layers.Dense(DIM_1, activation=ACTIVATION)(x)         # Nivel 1\n",
    "reconstructed = keras.layers.Dense(INPUT_SHAPE[0])(x)           # Nivel 0 (espacio base)\n",
    "decoder = keras.Model(encoded_z, reconstructed)                 # Modelo decodificador: codificación en espacio latente -> datos reconstruidos\n",
    "```\n",
    "\n",
    "**Autocodificador**\n",
    "```python\n",
    "autoencoder = keras.Model(input, reconstructed)                 # Modelo autocodificador: datos de entrada -> datos reconstruidos\n",
    "```\n",
    "\n",
    "El objetivo de esta sesión de prácticas es implementar un modelo de apredizaje automático basado en un *autoencoder* para la detección de anomalías en ECGs. Para ello se entrenará un *autoencoder* solo con ECGs normales, y luego se evaluará su capacidad de detección de latidos anómalos en un conjunto mixto (normales y anómalos) de ECGs, haciendo uso para ello de un umbral en el error de reconstrucción. A continuación se muestra un ejemplo de codificación-decodificación.\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; padding:5px solid #333333;\">\n",
    "    <img src=\"imgs/AE_ECGs.png\" style=\"height:800px; width:auto;\">\n",
    "</div>\n",
    "\n",
    "- Usaremos el [coeficiente de determinación $R^2$](https://es.wikipedia.org/wiki/Coeficiente_de_determinaci%C3%B3n) para estimar la fidelidad de la señal reconstruida: similitud de la señal recuperada con la original, a nivel de coeficiene $R^2$.\n",
    "\n",
    "```python\n",
    "    r2 = np.zeros(len(x_test))\n",
    "    for i in range(len(x_test)):\n",
    "        r2[i] = r2_score(x_test[i].flatten(), decoded[i].flatten())\n",
    "    r2 = r2.mean()\n",
    "    print(f\"Calidad de reconstrucción (coeficiente R2 medio): {r2*100:.2f} %\")\n",
    "```\n",
    "\n",
    "- Estimaremos también la hipotética compresión o reducción de la dimensionalidad que conlleva la codificación alcanzada en el espacio latente: cociente entre el número de características de la muestra original y la dimensión de su codificación en el espacio latente.\n",
    "\n",
    "```python\n",
    "    print(f\"Compresión de la codificación: {LATENT_DIM/np.prod(INPUT_SHAPE)*100:.2f} %\")\n",
    "```\n",
    "\n",
    "- Por último, prestaremos atención a los posibles valores nulos de la codificación alcanzada en el espacio latente (es este ejemplo no los habrá), lo que en su caso indicaría una codificación dispersa (*sparse*).\n",
    "\n",
    "```python\n",
    "    print(f\"Coeficientes no nulos: {np.count_nonzero(np.sum(encoded, axis=0)):d}/{LATENT_DIM}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03013e",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ejercicios'></a>\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "**E1:** Descargue el [dataset ECG5000 simplificado](http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv), lea el CSV y genere las variables de trabajo: registros ECGs normales y anómalos por separado, así como las correspondientes etiquetas de cada uno de ellos (reetiquete clase 0 -> normal, clase 1 -> anómalo). Particione el conjunto de entrenamiento (70% de los ECGs normales) y el conjunto de test (30% restante de los ECGs normales, más todos del ECGs anómalos).\n",
    "\n",
    "**E2:** Siguiendo la guía indicada en el aparado que introduce los [*autoencoders* totalmente conectados](#autoencoder):\n",
    "- Diseñe la pirámide de codificación-decodificación totalmente conectada, de 3 niveles de profundidad (2 niveles de profundidad adicionales al espacio latente). Utilice para ello secuencias de capas densas decrecientes-crecientes en potencias de 2, y con activación ReLU (salvo en el espacio latente).\n",
    "- Entrene el modelo empleando optimizador Adam y el error absoluto medio o MAE (Mean Absolute Error) como función de pérdida. Es imprescindible implementar la parada anticipada para evitar el sobreajuste.\n",
    "- De forma similar a la figura del apartado de [*autoencoders* totalmente conectados](#autoencoder), represente ejemplos de ECGs del conjunto de entrenamiento, con sus correspondientes codificaciones y reconstrucciones para diferentes dimensiones (potencia de 2) del espacio latente.\n",
    "\n",
    "**E3:** Evalúe  el modelo entrenado sobre el conjunto de test. Con el objetivo de comparar las diferencias en cuanto a la fidelidad de la reconstrucción de los ECGs normales y los anómalos:\n",
    "- Represente al menos un ECG de cada tipo (ECG normal y anómalo), superpuesto en la misma gráfica con su correspondiente reconstrucción.\n",
    "- Constate esta diferencia calculando los valores numéricos de MAE que se alcanzan para cada tipo de ECG.\n",
    "- Represente el histograma de los errores MAE de reconstrucción del conjunto de test, y compárelo con el histograma del entrenamiento (se recomienda representar ambos histogramas en la misma gráfica).\n",
    "\n",
    "**E4:** En base a los resultados anteriores, razone si se observa presumible separabilidad por umbral entre los ECGs normales y anómalas del conjunto de test, y estime un posible valor umbral (un cierto percentil de los errores MAE de reconstrucción del conjunto de test) que permita la separación (detección) de los ECGs anómalos. Según este criterio, un registro del conjunto de test se considerará anómalo si su MAE de reconstrucción supera dicho umbral. Aplique el umbral de detección, y clasifique los registros ECG del conjunto de test en \"normales\" o \"anómalos\"\n",
    "\n",
    "**E5:** Si se desean unas prestaciones de sensibilidad mínima de detección de ECGs anómalos del 99%, calcule la [especificidad esperable](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SpecificityAtSensitivity) (el valor objetivo estaría cercano o superando el 95%). Experimente con el aumento o disminución en potencias de 2 del número de neuronas de la pirámide del *autoencoder* o el umbral de detección. Experimente también el beneficio que aporta la [estandarización inicial](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de los registros ECG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.503705,
   "end_time": "2024-09-10T18:50:39.408748",
   "environment_variables": {},
   "exception": null,
   "input_path": "./s02.ipynb",
   "output_path": "/home/rufernan/local/DOCENCIA/_2024_2025/C1_PI/PRACTICAS/s02/s02.ipynb",
   "parameters": {},
   "start_time": "2024-09-10T18:50:24.905043",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
