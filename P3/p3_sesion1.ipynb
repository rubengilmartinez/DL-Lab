{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2beefb42-301d-4e46-ab61-ddf4deac263c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "        word-wrap: break-word;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div style=\"display:flex; justify-content:space-around; align-items:center; background-color:#cccccc; padding:5px; border:2px solid #333333;\">\n",
    "    <a href=\"https://www.um.es/web/estudios/grados/ciencia-ingenieria-datos/\" target=\"_blank\">\n",
    "    <img src=\"https://www.um.es/documents/1073494/42130150/LogosimboloUMU-positivo.png\" alt=\"UMU\" style=\"height:200px; width:auto;\">\n",
    "    <a href=\"https://estudios.upct.es/grado/5251/inicio\" target=\"_blank\">\n",
    "    <img src=\"https://www.upct.es/contenido/universidad/galeria/identidad-2021/logos/logos-upct/marca-upct/marca-principal/horizontal/azul.png\" alt=\"UPCT\" style=\"height:145px; width:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea66a83-0cbc-43cd-8082-bc82bcd9f133",
   "metadata": {},
   "source": [
    "# Asignatura: **Deep Learning**\n",
    "\n",
    "## Titulación: **Grado en Ciencia e Ingeniería de Datos**\n",
    "\n",
    "## Práctica 3: Transformers\n",
    "### **Sesión 1/3: Preprocesamiento de secuencias de caracteres**\n",
    "\n",
    "**Autores**: Antonio Martínez Sánchez, Juan Morales Sánchez, José Luís Sancho Gómez y Juan Antonio Botía Blaya\n",
    "\n",
    "<div style=\"page-break-before: always;\"></div>\n",
    "\n",
    "### Contenidos\n",
    "- [Requisitos](#requisitos)\n",
    "- [El dataset](#dataset)\n",
    "- [Codificación](#code)\n",
    "- [El problema: clasificación de péptidos](#problema)\n",
    "- [Ejercicios](#ejercicios)\n",
    "\n",
    "### Requisitos\n",
    "<a class='anchor' id='requisitos'></a>\n",
    "\n",
    "Se trabajará con notebooks de [Jupyter](https://jupyter.org/install) con código Python empleando como intérprete la última versión de [Miniconda](https://docs.anaconda.com/miniconda/). Se requiere la preinstalación (se recomienda utilizar [pip](https://pypi.org/project/pip/)) de los siguientes paquetes de Python:\n",
    "\n",
    "- [Numpy](https://pypi.org/project/numpy/) (computación numérica)\n",
    "- [Tensorflow](https://www.tensorflow.org/install/pip?hl=es-419#linux) que incluye a Keras (deep learning)\n",
    "- [Scikit-learn](https://pypi.org/project/scikit-learn/) (machine learning)\n",
    "- [Matplotlib](https://pypi.org/project/matplotlib/) (visualización de datos)\n",
    "- [Pandas](https://pypi.org/project/seaborn/) (manipulación de datos tabulados)\n",
    "\n",
    "### El dataset\n",
    "<a class='anchor' id='dataset'></a>\n",
    "\n",
    "Los péptidos son moléculas biológicas formadas por secuencias cortas de aminoácidos, pudiendo llegar hasta aproximadamente los 100 aminoácidos, a partir de esta cantidad a un péptido se le suele denominar proteína. Los aminoácidos (AA) son los ladrillos de los péptidos, que a su vez son los componentes fundamentales de la estructura y maquinaria celular. Las secuencias de AA que determinan la estructura y función de un péptido están codificadas en los genes, las unidades de información almacenadas en el ADN de los seres vivos. Un gen es un fragmento de ADN que contine una secuencia de nucleótidos que es **transcrito** a un fragmento de ARNm (un intermediario que mantiene la información) y que al alcanzar un ribosoma (la fábrica de péptidos) es **trasladado** a una secuencia de AA. Esta secuencia determina como el péptidos deben plegarse sobre si mismos para generar la estructura 3D que le confiere sus propiedades físico-químicas. Por tanto, estudiando la secuencia de AA de un péptido se puede determinar su función y analizar su función biológica.\n",
    "\n",
    "![ADN_to_AA](figs/ADN_AA_traduccion.jpg)\n",
    "\n",
    "Los datos a procesar en esta práctica son dos tablas almacenadas en formato CSV con la secuencia de AAs de una serie de péptidos. La primera columna contine el identificador de los péptidos, para nostros no tiene mayor relevancia. La columna 'aa_seq' contiene la secuencia de AAs codificada con caracteres en mayúscula, cada carácter se corresponde con un AA. Finalmente, la columna 'AMP' determina si este péptido tiene algún efecto antimicrobiano. Cada tabla contiene péptidos diferentes, la tabla *non_amp_ampep_cdhit90.csv* contine péptidos sin efecto antimicrobiano y la tabla *veltri_dramp_cdhit_90.csv' contine péptidos con efecto antimicrobiano o clasificados como AMP.\n",
    "\n",
    "### Codificación\n",
    "<a class='anchor' id='code'></a>\n",
    "\n",
    "Las redes neuronales procesan tensores cuyos valores son numéricos. No obstante, en algunos casos los datos de partida son conjuntos o secuencias de caracteres. El ejemplo más claro es el texto, por ejemplo, este párrafo contine una secuencia de caracteres que, si obviamos los signos de puntuación y acentuación, está formado por las letras del abecedario. En el contexto del lenguaje expresado en este párrafo, los carácteres no tienen ningún significado (semántica) de forma aislada. De forma simplista podemos asumir que las unidades semánticas, o **tokens**, del lenguaje natural son las palabras. Puesto que una red neuronal no puede procesar directamente los tokens en forma de palabras, es necesario codificaros previamente empleando valores numéricos. El **vocabulario** de un lenguaje es el conjunto de los diferentes tokens, en caso de los lenguajes naturales puede tener cientos de miles de elementos dificultando su codificación.\n",
    "\n",
    "El dataset de esta práctica está expresado en un lenguaje más sencillo y menos ambiguo que el lenguaje natural pero también codificable en forma de texto. En este caso, los tokens están claramente definidos y se corresponden con cada carácter de la secuencia de AA de un péptido, de tal modo, que cada carácter identifica unívocamente un AA. Por tanto, el vocabulario del lenguaje de los péptidos se limita a un conjunto reducido de AA representados en un fichero CSV con caracteres individuales (letras mayúsculas). Un péptido se corresponde con una secuencia de AAs (letras) cuya longitud es variable. \n",
    "\n",
    "En esta práctica utilizaremos los métodos de codificación más directos:\n",
    "\n",
    "---\n",
    "\n",
    "**CODIFICACIÓN.**\n",
    "\n",
    "- Integer: se construye una tabla con todos los tokens considerados y se le asigna un índice entero a cada token. Luego a cada token de la secuencia se le asigna el índice correspondiente. Como las secuencias tienen tamaños diferentes, se suele configurar para que los vectores de salida tengan el tamaño de la secuencia más larga asignándose un 0 a los valores de relleno (*padding*).\n",
    "\n",
    "- Multi-hot: la codificación de salida es un vector binario cuyo tamaño es el número de tokens considerados, si un token aparece en la secuencia codificada el vector tendrá un 1 en la posición correspondiente a ese token, si no un 0. Independientemente del tamaño de la secuencia a codificar, la salida será un vector cuyo tamaño se corresponde con la longitud del vocabulario. # |V| TAMAÑO DEL VECTOR PARA CADA TOKEN\n",
    "\n",
    "- TF-IDF: es una extensión de multi-hot que en lugar de valores binarios asigna la frecuencia de aparición de un token en un conjunto de datos.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "La librería Keras proporciona la clase [TextVectorization](https://keras.io/api/layers/preprocessing_layers/text/text_vectorization/) que implementa una capa para la codificación de texto.\n",
    "\n",
    "### El problema: clasificación de péptidos\n",
    "<a class='anchor' id='problema'></a>\n",
    "\n",
    "Durante esta práctica abordaremos el problema de la clasificación de fragmentos de texto. En concreto, nos centraremos en la clasificación de péptidos, secuencias de AAs, codificadas mediante caracteres de texto. Los péptidos se pueden agrupar en dos clases según presenten o no actividad antimicrobiana (AMP). Los CSV de entrada están separados entre los AMP y los no AMP, así que deberán fusionarse para construir un dataset que permita un entrenamiento supervisado.\n",
    "\n",
    "En las diferentes sesiones de esta práctica construiremos diferentes modelos para resolver este problema. El punto de partida será la arquitectura genérica MLP, utilizaremos también redes neuronales recurrentes (RNN) para estudiar la ventaja de procesar datos en forma de secuencia y finalmente implementaremos un Transformer que se ha convertido en el modelo de referencia para este tipo de datos.\n",
    "\n",
    "### Ejercicios\n",
    "<a class='anchor' id='ejercicios'></a>\n",
    "\n",
    "**E1:** Carga las tablas almacenadas en los CSV utilizando la librería Pandas y fusiónalas en un solo Dataframe. Después construye una lista con todos los péptidos y otra cuyos elementos sean booleanos identificando si son AMP. ¿Cuál es la secuencia más larga? ¿Cuántos AAs diferentes hay? ¿Cuál es el vocabulario del lenguaje?\n",
    "\n",
    "**E2:** Divide los conjuntos de datos del E1 en dos. Uno que contenga el 80% de las secuencias para el entrenamiento supervisado y otro que contenga al resto para testear los modelos entrenados. Asegúrate que en ambos conjuntos hay una selección representativos de péptidos.\n",
    "\n",
    "**E3:** Codifica los péptidos empleando la codificación multi-hot. ¿Qué longitud tiene cada péptido codificado?\n",
    "\n",
    "**E4:** Basándote en la arquitectura del E4 de la Sesión 1 de la Práctica 2 (Redes Convolucionales), construye un MLP para clasificar los péptidos. ¿Cuántos parámetros a entrenar tiene?\n",
    "\n",
    "**E5:** Entrena el modelo del E4 utilizando el 20% de los datos de entrenamiento para validación durante el entrenamiento. Utiliza una cantidad de épocas que produzca sobreajuste, además añade un *callback* para guardar el modelo que tenga una mayor precisión en la validación.\n",
    "\n",
    "**E6:** Testea la precisión del modelo entrenado en el E5 empleando el conjunto de test obtenido en el E2. Recuerda cargar el modelo para la mejor época. ¿Qué precisión se alcanza?\n",
    "\n",
    "**E7:** Repite los ejercicios E3-6 pero esta vez empleando codificación TF-IDF. ¿Ha mejorado la precisión? ¿por qué?\n",
    "\n",
    "**E8:** Hasta ahora hemos trabajado solo con unigramas, los tokens están compuesto por AAs aislados. También es posible construir tokens con combinaciones de AAs (n-gramas). Repite el ejercicio E7 pero esta vez empleando bigramas. ¿Qué tamaño tiene el vocabulario ahora? ¿Por qué MLP ha aumentado considerablemente el número de parámetros a entrenar? ¿Qué ventaja podría aportar el trabajar con n-gramas (n > 1) en comparación de unigramas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628363a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11eb5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONJUNTO DE ENTRENAMIENTO DE LA CODIFICACIÓN: TODOS LAS CADENAS DE AMINOACIDOS, UTILIZAR ADAPT Y EMPLEAR PARA CODIFICAR CORRECTAMENTE CADA CARÁCTER DENTRO DE LA CADENA\n",
    "\n",
    "peptidos_AM = pd.read_csv('../data/dataset_p3/veltri_dramp_cdhit_90.csv', sep=',')\n",
    "\n",
    "perptidos_sin_efecto_AM =  pd.read_csv('../data/dataset_p3/non_amp_ampep_cdhit90.csv', sep=',')\n",
    "#ENTRADA: CADENA DE CARÁCTERES Y SALIDA: VECTOR CODIFICADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb43c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptidos_AM.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "perptidos_sin_efecto_AM.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
